{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c6d1a4",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d8a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6622a8e",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e429df43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  881 chunks from page\n",
      "Loaded 1540 chunks from fixed_size\n",
      "Loaded 1577 chunks from sentence\n",
      "\n",
      "Total chunking strategies: 3\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path('processed_data')\n",
    "VECTOR_STORE_DIR = Path('vector_stores')\n",
    "VECTOR_STORE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "chunking_methods = ['page', 'fixed_size', 'sentence']\n",
    "chunks_data = {}\n",
    "\n",
    "for method in chunking_methods:\n",
    "    file_path = DATA_DIR / f'chunks_{method}.json'\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        chunks_data[method] = json.load(f)\n",
    "    print(f\"Loaded {len(chunks_data[method]):4d} chunks from {method}\")\n",
    "\n",
    "print(f\"\\nTotal chunking strategies: {len(chunking_methods)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b91a76",
   "metadata": {},
   "source": [
    "## 3. Initialize Embedding Models\n",
    "\n",
    "We'll compare two embedding models:\n",
    "1. **nomic-ai/nomic-embed-text-v1.5**: Modern model with 768 dims, 8192 token context\n",
    "2. **all-MiniLM-L6-v2**: Classic baseline with 384 dims, 512 token context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bda6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nomic model loaded successfully on GPU\n",
      "Embedding dimension: 768\n",
      "Sample embedding (first 10 dims): [ 1.2799681   0.4015842  -3.5162659  -0.39813256  1.5919122   0.36983135\n",
      "  0.6751001  -0.6361028   0.6404002  -0.42047468]\n",
      "\n",
      "minilm model loaded successfully on GPU\n",
      "Embedding dimension: 384\n",
      "Sample embedding (first 10 dims): [ 0.08429644  0.05795367  0.00449339  0.10582107  0.00708342 -0.0178447\n",
      " -0.01688805 -0.01522829  0.04047313  0.03342254]\n"
     ]
    }
   ],
   "source": [
    "embedding_models = {\n",
    "    'nomic': SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True, device='cuda'),\n",
    "    'minilm': SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "}\n",
    "\n",
    "for name, model in embedding_models.items():\n",
    "    test_embedding = model.encode(\"This is a test sentence.\")\n",
    "    print(f\"\\n{name} model loaded successfully on GPU\")\n",
    "    print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "    print(f\"Sample embedding (first 10 dims): {test_embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380425b",
   "metadata": {},
   "source": [
    "## 4. Create Embeddings for Each Chunking Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94af88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating embeddings for page using nomic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f8fd30725c44aa89b3ab4b7dc1e99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 881 embeddings of dimension 768\n",
      "Saved embeddings to vector_stores\\embeddings_nomic_page.npy\n",
      "\n",
      "Creating embeddings for fixed_size using nomic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0df66bae7e74d81bb20d45ec2cebb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1540 embeddings of dimension 768\n",
      "Saved embeddings to vector_stores\\embeddings_nomic_fixed_size.npy\n",
      "\n",
      "Creating embeddings for sentence using nomic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0aba8df84e4cc1a70d0fdee6f5255f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1577 embeddings of dimension 768\n",
      "Saved embeddings to vector_stores\\embeddings_nomic_sentence.npy\n",
      "\n",
      "Creating embeddings for page using minilm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8818a37f4ac5497c86c7db2869dd5439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 881 embeddings of dimension 384\n",
      "Saved embeddings to vector_stores\\embeddings_minilm_page.npy\n",
      "\n",
      "Creating embeddings for fixed_size using minilm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4f3f2ef8ca4297bc1efe4e017d4ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1540 embeddings of dimension 384\n",
      "Saved embeddings to vector_stores\\embeddings_minilm_fixed_size.npy\n",
      "\n",
      "Creating embeddings for sentence using minilm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855a7c4ddd1b4f8db65af83b9bca64d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1577 embeddings of dimension 384\n",
      "Saved embeddings to vector_stores\\embeddings_minilm_sentence.npy\n",
      "\n",
      "\n",
      "\n",
      "NOMIC embeddings:\n",
      "  page           :  881 embeddings x 768 dims\n",
      "  fixed_size     : 1540 embeddings x 768 dims\n",
      "  sentence       : 1577 embeddings x 768 dims\n",
      "\n",
      "MINILM embeddings:\n",
      "  page           :  881 embeddings x 384 dims\n",
      "  fixed_size     : 1540 embeddings x 384 dims\n",
      "  sentence       : 1577 embeddings x 384 dims\n"
     ]
    }
   ],
   "source": [
    "def create_embeddings(chunks, method_name, embedding_model, model_name, batch_size=32):\n",
    "    print(f\"\\nCreating embeddings for {method_name} using {model_name}\")\n",
    "    \n",
    "    texts = [chunk['text'] for chunk in chunks]\n",
    "    \n",
    "    embeddings = embedding_model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Created {len(embeddings)} embeddings of dimension {embeddings.shape[1]}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "embeddings_data = {}\n",
    "\n",
    "for model_name, model in embedding_models.items():\n",
    "    embeddings_data[model_name] = {}\n",
    "    for method in chunking_methods:\n",
    "        embeddings = create_embeddings(chunks_data[method], method, model, model_name)\n",
    "        embeddings_data[model_name][method] = embeddings\n",
    "        \n",
    "        embeddings_file = VECTOR_STORE_DIR / f'embeddings_{model_name}_{method}.npy'\n",
    "        np.save(embeddings_file, embeddings)\n",
    "        print(f\"Saved embeddings to {embeddings_file}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for model_name in embedding_models.keys():\n",
    "    print(f\"\\n{model_name.upper()} embeddings:\")\n",
    "    for method, emb in embeddings_data[model_name].items():\n",
    "        print(f\"  {method:15s}: {emb.shape[0]:4d} embeddings x {emb.shape[1]} dims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472acc5",
   "metadata": {},
   "source": [
    "## 5. Build Vector Store (ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127c4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating ChromaDB collection for page with nomic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd19e6d829584fda95cdbfefcccb7b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 881 documents to collection 'survival_nomic_page'\n",
      "\n",
      "Creating ChromaDB collection for fixed_size with nomic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3886fa9bb8c24ffebe1f6179a8236b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1540 documents to collection 'survival_nomic_fixed_size'\n",
      "\n",
      "Creating ChromaDB collection for sentence with nomic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720ae0acf43c4951bdd3611bd8264634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1577 documents to collection 'survival_nomic_sentence'\n",
      "\n",
      "Creating ChromaDB collection for page with minilm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce8fa9734d1461d95720edfcdb3993b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 881 documents to collection 'survival_minilm_page'\n",
      "\n",
      "Creating ChromaDB collection for fixed_size with minilm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496dec67b2b4420598b12370fe3f1b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1540 documents to collection 'survival_minilm_fixed_size'\n",
      "\n",
      "Creating ChromaDB collection for sentence with minilm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278dac94600340bcbe72b18a2899f842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1577 documents to collection 'survival_minilm_sentence'\n"
     ]
    }
   ],
   "source": [
    "def create_chroma_collection(method_name, model_name, chunks, embeddings):\n",
    "    print(f\"\\nCreating ChromaDB collection for {method_name} with {model_name}\")\n",
    "    \n",
    "    chroma_client = chromadb.PersistentClient(\n",
    "        path=str(VECTOR_STORE_DIR / 'chroma_db')\n",
    "    )\n",
    "\n",
    "    collection_name = f\"survival_{model_name}_{method_name}\"\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"chunking_method\": method_name, \"model\": model_name}\n",
    "    )\n",
    "    \n",
    "    ids = [f\"{model_name}_{chunk['chunk_id']}\" for chunk in chunks]\n",
    "    documents = [chunk['text'] for chunk in chunks]\n",
    "    metadatas = [{\n",
    "        'source': chunk['source'],\n",
    "        'chunk_method': chunk['chunk_method'],\n",
    "        'model': model_name\n",
    "    } for chunk in chunks]\n",
    "    \n",
    "    batch_size = 100\n",
    "    for i in tqdm(range(0, len(ids), batch_size), desc=\"Adding to ChromaDB\"):\n",
    "        batch_end = min(i + batch_size, len(ids))\n",
    "        collection.add(\n",
    "            ids=ids[i:batch_end],\n",
    "            embeddings=embeddings[i:batch_end].tolist(),\n",
    "            documents=documents[i:batch_end],\n",
    "            metadatas=metadatas[i:batch_end]\n",
    "        )\n",
    "    \n",
    "    print(f\"Added {len(ids)} documents to collection '{collection.name}'\")\n",
    "    return collection\n",
    "\n",
    "chroma_collections = {}\n",
    "\n",
    "for model_name in embedding_models.keys():\n",
    "    chroma_collections[model_name] = {}\n",
    "    for method in chunking_methods:\n",
    "        collection = create_chroma_collection(\n",
    "            method,\n",
    "            model_name,\n",
    "            chunks_data[method],\n",
    "            embeddings_data[model_name][method]\n",
    "        )\n",
    "        chroma_collections[model_name][method] = collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7572b8",
   "metadata": {},
   "source": [
    "## 6. Implement TF-IDF Indices\n",
    "\n",
    "Create TF-IDF indices for the classic sparse baseline comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71c0664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating TF-IDF index for page\n",
      "TF-IDF index created with 881 documents\n",
      "Vocabulary size: 10000\n",
      "Saved to vector_stores\\tfidf_page.pkl\n",
      "\n",
      "Creating TF-IDF index for fixed_size\n",
      "TF-IDF index created with 881 documents\n",
      "Vocabulary size: 10000\n",
      "Saved to vector_stores\\tfidf_page.pkl\n",
      "\n",
      "Creating TF-IDF index for fixed_size\n",
      "TF-IDF index created with 1540 documents\n",
      "Vocabulary size: 10000\n",
      "Saved to vector_stores\\tfidf_fixed_size.pkl\n",
      "\n",
      "Creating TF-IDF index for sentence\n",
      "TF-IDF index created with 1540 documents\n",
      "Vocabulary size: 10000\n",
      "Saved to vector_stores\\tfidf_fixed_size.pkl\n",
      "\n",
      "Creating TF-IDF index for sentence\n",
      "TF-IDF index created with 1577 documents\n",
      "Vocabulary size: 10000\n",
      "Saved to vector_stores\\tfidf_sentence.pkl\n",
      "TF-IDF index created with 1577 documents\n",
      "Vocabulary size: 10000\n",
      "Saved to vector_stores\\tfidf_sentence.pkl\n"
     ]
    }
   ],
   "source": [
    "def create_tfidf_index(chunks, method_name):\n",
    "    print(f\"\\nCreating TF-IDF index for {method_name}\")\n",
    "    \n",
    "    documents = [chunk['text'] for chunk in chunks]\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        max_features=10000,  \n",
    "        ngram_range=(1, 2), \n",
    "        min_df=2,\n",
    "        max_df=0.8\n",
    "    )\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    \n",
    "    tfidf_file = VECTOR_STORE_DIR / f'tfidf_{method_name}.pkl'\n",
    "    with open(tfidf_file, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'vectorizer': tfidf_vectorizer,\n",
    "            'matrix': tfidf_matrix\n",
    "        }, f)\n",
    "    \n",
    "    print(f\"TF-IDF index created with {len(documents)} documents\")\n",
    "    print(f\"Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "    print(f\"Saved to {tfidf_file}\")\n",
    "    \n",
    "    return tfidf_vectorizer, tfidf_matrix\n",
    "\n",
    "tfidf_indices = {}\n",
    "\n",
    "for method in chunking_methods:\n",
    "    tfidf_vectorizer, tfidf_matrix = create_tfidf_index(chunks_data[method], method)\n",
    "    tfidf_indices[method] = {\n",
    "        'vectorizer': tfidf_vectorizer,\n",
    "        'matrix': tfidf_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8b24c",
   "metadata": {},
   "source": [
    "## 7. Implement Retrieval Methods\n",
    "\n",
    "Compare three retrieval approaches:\n",
    "1. **Dense (nomic)**: Modern semantic embeddings (nomic-embed-text-v1.5)\n",
    "2. **Dense (minilm)**: Classic semantic baseline (all-MiniLM-L6-v2)\n",
    "3. **TF-IDF (sparse)**: Traditional term frequency baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39082105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalSystem:\n",
    "    \n",
    "    def __init__(self, method_name, chunks, chroma_collections, tfidf_index, embedding_models):\n",
    "        self.method_name = method_name\n",
    "        self.chunks = chunks\n",
    "        self.chroma_collections = chroma_collections \n",
    "        self.tfidf_vectorizer = tfidf_index['vectorizer']\n",
    "        self.tfidf_matrix = tfidf_index['matrix']\n",
    "        self.embedding_models = embedding_models \n",
    "    \n",
    "    def dense_retrieval(self, query, model_name='nomic', top_k=5):\n",
    "        query_embedding = self.embedding_models[model_name].encode([query])[0].tolist()\n",
    "        \n",
    "        results = self.chroma_collections[model_name].query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        retrieved_docs = []\n",
    "        for i, (doc_id, doc, distance) in enumerate(zip(\n",
    "            results['ids'][0],\n",
    "            results['documents'][0],\n",
    "            results['distances'][0]\n",
    "        )):\n",
    "            similarity = 1 / (1 + distance)\n",
    "            retrieved_docs.append({\n",
    "                'rank': i + 1,\n",
    "                'chunk_id': doc_id,\n",
    "                'text': doc,\n",
    "                'score': similarity,\n",
    "                'method': f'dense_{model_name}'\n",
    "            })\n",
    "        \n",
    "        return retrieved_docs\n",
    "    \n",
    "    def tfidf_retrieval(self, query, top_k=5):\n",
    "        query_vector = self.tfidf_vectorizer.transform([query])\n",
    "        \n",
    "        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        retrieved_docs = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            chunk = self.chunks[idx]\n",
    "            retrieved_docs.append({\n",
    "                'rank': i + 1,\n",
    "                'chunk_id': chunk['chunk_id'],\n",
    "                'text': chunk['text'],\n",
    "                'score': float(similarities[idx]),\n",
    "                'method': 'tfidf'\n",
    "            })\n",
    "        \n",
    "        return retrieved_docs\n",
    "    \n",
    "    def retrieve(self, query, method='dense_nomic', top_k=5):\n",
    "        if method == 'dense_nomic':\n",
    "            return self.dense_retrieval(query, model_name='nomic', top_k=top_k)\n",
    "        elif method == 'dense_minilm':\n",
    "            return self.dense_retrieval(query, model_name='minilm', top_k=top_k)\n",
    "        elif method == 'tfidf':\n",
    "            return self.tfidf_retrieval(query, top_k=top_k)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}. Use 'dense_nomic', 'dense_minilm', or 'tfidf'\")\n",
    "\n",
    "retrieval_systems = {}\n",
    "\n",
    "for method in chunking_methods:\n",
    "    retrieval_systems[method] = RetrievalSystem(\n",
    "        method_name=method,\n",
    "        chunks=chunks_data[method],\n",
    "        chroma_collections={\n",
    "            'nomic': chroma_collections['nomic'][method],\n",
    "            'minilm': chroma_collections['minilm'][method]\n",
    "        },\n",
    "        tfidf_index=tfidf_indices[method],\n",
    "        embedding_models=embedding_models\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8df84",
   "metadata": {},
   "source": [
    "## 8. Test Retrieval Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a64f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing retrieval methods with chunking strategy: sentence\n",
      "Query: 'How do I find water in the desert?'\n",
      "\n",
      "Retrieval method: DENSE_NOMIC\n",
      "\n",
      "Query: 'How do I find water in the desert?'\n",
      "\n",
      "Rank 1 | Score: 0.0063 | ID: nomic_FM3-05-70_sent_156\n",
      "Text: from cloth. Following are signs to watch for in the desert to help you find water: • All trails lead to water. You should follow in the direction in which the trails converge. Signs of camps, campfire...\n",
      "\n",
      "Rank 2 | Score: 0.0047 | ID: nomic_FM3-05-70_sent_387\n",
      "Text: LOW RAINFALL 13-11. Low rainfall is the most obvious environmental factor in an arid area. Some desert areas receive less than 10 centimeters (4 inches) of rain annually, and this rain comes in brief ...\n",
      "\n",
      "Rank 3 | Score: 0.0047 | ID: nomic_FM21-76_sent_288\n",
      "Text: • Intense sunlight and heat. • Wide temperature range. • Sparse vegetation. • High mineral content near ground surface. • Sandstorms. • Mirages. Low Rainfall Low rainfall is the most obvious environme...\n",
      "\n",
      "Retrieval method: DENSE_MINILM\n",
      "\n",
      "Query: 'How do I find water in the desert?'\n",
      "\n",
      "Rank 1 | Score: 0.6186 | ID: minilm_FM3-05-70_sent_156\n",
      "Text: from cloth. Following are signs to watch for in the desert to help you find water: • All trails lead to water. You should follow in the direction in which the trails converge. Signs of camps, campfire...\n",
      "\n",
      "Rank 2 | Score: 0.5818 | ID: minilm_FM3-05-70_sent_154\n",
      "Text: Do not drink seawater without desalting. Rain Catch rain in If tarp or water-holding material is tarps or in other coated with salt, wash it in the sea water-holding before using (very little salt wil...\n",
      "\n",
      "Rank 3 | Score: 0.5471 | ID: minilm_FM3-05-70_sent_394\n",
      "Text: You can see lights, red flashlights, and blackout lights at great distances. Sound carries very far. 13-28. Conversely, during nights with little moonlight, visibility is extremely poor. Traveling is ...\n",
      "\n",
      "Retrieval method: TFIDF\n",
      "\n",
      "Query: 'How do I find water in the desert?'\n",
      "\n",
      "Rank 1 | Score: 0.2273 | ID: FM21-76_sent_302\n",
      "Text: A light color means you are drinking enough water, a dark color means you need to drink more. DESERT HAZARDS There are several hazards unique to desert survival. These include insects, snakes, thorned...\n",
      "\n",
      "Rank 2 | Score: 0.2008 | ID: FM3-05-70_sent_403\n",
      "Text: • Drink water at least once an hour. • Get in the shade when resting; do not lie directly on the ground. • Do not take off your shirt and work during the day. • Check the color of your urine. A light ...\n",
      "\n",
      "Rank 3 | Score: 0.2002 | ID: FM3-05-70_sent_829\n",
      "Text: To make tea, dry the leaves and soak them in hot water. You can eat the roasted seeds. CAUTION Some persons are unable to digest persimmon pulp. Unripe persimmons are highly astringent and inedible. B...\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"How do I find water in the desert?\",\n",
    "    \"What should I do if I encounter a snake?\",\n",
    "    \"How to build a shelter in cold weather?\"\n",
    "]\n",
    "\n",
    "def display_results(query, results, show_text=True):\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"\\nRank {result['rank']} | Score: {result['score']:.4f} | ID: {result['chunk_id']}\")\n",
    "        if show_text:\n",
    "            text_preview = result['text'][:200] + \"...\" if len(result['text']) > 200 else result['text']\n",
    "            print(f\"Text: {text_preview}\")\n",
    "\n",
    "test_query = test_queries[0]\n",
    "test_chunking = 'sentence'\n",
    "\n",
    "print(f\"\\nTesting retrieval methods with chunking strategy: {test_chunking}\")\n",
    "print(f\"Query: '{test_query}'\")\n",
    "\n",
    "retriever = retrieval_systems[test_chunking]\n",
    "\n",
    "for retrieval_method in ['dense_nomic', 'dense_minilm', 'tfidf']:\n",
    "    print(f\"\\nRetrieval method: {retrieval_method.upper()}\")\n",
    "    \n",
    "    results = retriever.retrieve(test_query, method=retrieval_method, top_k=3)\n",
    "    display_results(test_query, results, show_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a5add",
   "metadata": {},
   "source": [
    "## 9. Compare All Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e46448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'How to purify water for drinking?'\n",
      "Chunking        | Retrieval       | Top 3 Results (Score | Preview)                                                      \n",
      "page            | dense_nomic     | 0.005: You will need at least three stills to meet your individual daily water intake n... | 0.005: Figure 6-9. Belowground Still to Get Potable Water From Polluted Water WATER PUR... | 0.005: Note: These procedures only clear the water and make it more palatable. You will... | \n",
      "page            | dense_minilm    | 0.662: Figure 6-9. Belowground Still to Get Potable Water From Polluted Water WATER PUR... | 0.628: You will need at least three stills to meet your individual daily water intake n... | 0.549: Note: If you do not have a canteen, a cup, a can, or other type of container, im... | \n",
      "page            | tfidf           | 0.226: You will need at least three stills to meet your individual daily water intake n... | 0.218: Figure 6-9. Belowground Still to Get Potable Water From Polluted Water WATER PUR... | 0.140: Note: These procedures only clear the water and make it more palatable. You will... | \n",
      "page            | dense_nomic     | 0.005: You will need at least three stills to meet your individual daily water intake n... | 0.005: Figure 6-9. Belowground Still to Get Potable Water From Polluted Water WATER PUR... | 0.005: Note: These procedures only clear the water and make it more palatable. You will... | \n",
      "page            | dense_minilm    | 0.662: Figure 6-9. Belowground Still to Get Potable Water From Polluted Water WATER PUR... | 0.628: You will need at least three stills to meet your individual daily water intake n... | 0.549: Note: If you do not have a canteen, a cup, a can, or other type of container, im... | \n",
      "page            | tfidf           | 0.226: You will need at least three stills to meet your individual daily water intake n... | 0.218: Figure 6-9. Belowground Still to Get Potable Water From Polluted Water WATER PUR... | 0.140: Note: These procedures only clear the water and make it more palatable. You will... | \n",
      "fixed_size      | dense_nomic     | 0.006: ough holds the polluted water and the soil filters it as the still draws it. The... | 0.005: at least three stills to meet your individual daily water intake needs. In compa... | 0.005: en where your mouth touches. 6-31. Purify water by the following methods: • Use ... | \n",
      "fixed_size      | dense_minilm    | 0.671: at least three stills to meet your individual daily water intake needs. In compa... | 0.657: ough holds the polluted water and the soil filters it as the still draws it. The... | 0.547: en where your mouth touches. 6-31. Purify water by the following methods: • Use ... | \n",
      "fixed_size      | tfidf           | 0.274: ough holds the polluted water and the soil filters it as the still draws it. The... | 0.225: at least three stills to meet your individual daily water intake needs. In compa... | 0.210:  These procedures only clear the water and make it more palatable. You will have... | \n",
      "fixed_size      | dense_nomic     | 0.006: ough holds the polluted water and the soil filters it as the still draws it. The... | 0.005: at least three stills to meet your individual daily water intake needs. In compa... | 0.005: en where your mouth touches. 6-31. Purify water by the following methods: • Use ... | \n",
      "fixed_size      | dense_minilm    | 0.671: at least three stills to meet your individual daily water intake needs. In compa... | 0.657: ough holds the polluted water and the soil filters it as the still draws it. The... | 0.547: en where your mouth touches. 6-31. Purify water by the following methods: • Use ... | \n",
      "fixed_size      | tfidf           | 0.274: ough holds the polluted water and the soil filters it as the still draws it. The... | 0.225: at least three stills to meet your individual daily water intake needs. In compa... | 0.210:  These procedures only clear the water and make it more palatable. You will have... | \n",
      "sentence        | dense_nomic     | 0.006: Rainwater collected in clean containers or in plants is usually safe for drinkin... | 0.005: However, purify water from lakes, ponds, swamps, springs, or streams, especially... | 0.005: • Use potassium permanganate, commonly marketed as Condy’s Crystals, for a numbe... | \n",
      "sentence        | dense_minilm    | 0.667: Rainwater collected in clean containers or in plants is usually safe for drinkin... | 0.660: However, purify water from lakes, ponds, swamps, springs, or streams, especially... | 0.558: However, always purify the water before drinking it. During the summer months, t... | \n",
      "sentence        | tfidf           | 0.248: However, purify water from lakes, ponds, swamps, springs, or streams, especially... | 0.245: Rainwater collected in clean containers or in plants is usually safe for drinkin... | 0.162: However, always purify the water before drinking it. During the summer months, t... | \n",
      "========================================================================================================================\n",
      "sentence        | dense_nomic     | 0.006: Rainwater collected in clean containers or in plants is usually safe for drinkin... | 0.005: However, purify water from lakes, ponds, swamps, springs, or streams, especially... | 0.005: • Use potassium permanganate, commonly marketed as Condy’s Crystals, for a numbe... | \n",
      "sentence        | dense_minilm    | 0.667: Rainwater collected in clean containers or in plants is usually safe for drinkin... | 0.660: However, purify water from lakes, ponds, swamps, springs, or streams, especially... | 0.558: However, always purify the water before drinking it. During the summer months, t... | \n",
      "sentence        | tfidf           | 0.248: However, purify water from lakes, ponds, swamps, springs, or streams, especially... | 0.245: Rainwater collected in clean containers or in plants is usually safe for drinkin... | 0.162: However, always purify the water before drinking it. During the summer months, t... | \n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_query = \"How to purify water for drinking?\"\n",
    "\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(f\"{'Chunking':<15} | {'Retrieval':<15} | {'Top 3 Results (Score | Preview)':<85}\")\n",
    "\n",
    "for chunking in chunking_methods:\n",
    "    for retrieval_method in ['dense_nomic', 'dense_minilm', 'tfidf']:\n",
    "        retriever = retrieval_systems[chunking]\n",
    "        results = retriever.retrieve(test_query, method=retrieval_method, top_k=3)\n",
    "        \n",
    "        result_str = \"\"\n",
    "        for r in results:\n",
    "            preview = r['text'][:80].replace('\\n', ' ')\n",
    "            result_str += f\"{r['score']:.3f}: {preview}... | \"\n",
    "        \n",
    "        print(f\"{chunking:<15} | {retrieval_method:<15} | {result_str}\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d5a95",
   "metadata": {},
   "source": [
    "## 10. Save Retrieval Systems Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0092abf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to vector_stores\\retrieval_config.json\n",
      "\n",
      "Configuration:\n",
      "{\n",
      "  \"embedding_models\": {\n",
      "    \"nomic\": {\n",
      "      \"name\": \"nomic-ai/nomic-embed-text-v1.5\",\n",
      "      \"dims\": 768,\n",
      "      \"context_length\": 8192\n",
      "    },\n",
      "    \"minilm\": {\n",
      "      \"name\": \"all-MiniLM-L6-v2\",\n",
      "      \"dims\": 384,\n",
      "      \"context_length\": 512\n",
      "    }\n",
      "  },\n",
      "  \"chunking_methods\": [\n",
      "    \"page\",\n",
      "    \"fixed_size\",\n",
      "    \"sentence\"\n",
      "  ],\n",
      "  \"retrieval_methods\": [\n",
      "    \"dense_nomic\",\n",
      "    \"dense_minilm\",\n",
      "    \"tfidf\"\n",
      "  ],\n",
      "  \"collections\": {\n",
      "    \"page\": {\n",
      "      \"num_chunks\": 881,\n",
      "      \"nomic_embedding_file\": \"embeddings_nomic_page.npy\",\n",
      "      \"minilm_embedding_file\": \"embeddings_minilm_page.npy\",\n",
      "      \"tfidf_file\": \"tfidf_page.pkl\",\n",
      "      \"chroma_nomic_collection\": \"survival_nomic_page\",\n",
      "      \"chroma_minilm_collection\": \"survival_minilm_page\"\n",
      "    },\n",
      "    \"fixed_size\": {\n",
      "      \"num_chunks\": 1540,\n",
      "      \"nomic_embedding_file\": \"embeddings_nomic_fixed_size.npy\",\n",
      "      \"minilm_embedding_file\": \"embeddings_minilm_fixed_size.npy\",\n",
      "      \"tfidf_file\": \"tfidf_fixed_size.pkl\",\n",
      "      \"chroma_nomic_collection\": \"survival_nomic_fixed_size\",\n",
      "      \"chroma_minilm_collection\": \"survival_minilm_fixed_size\"\n",
      "    },\n",
      "    \"sentence\": {\n",
      "      \"num_chunks\": 1577,\n",
      "      \"nomic_embedding_file\": \"embeddings_nomic_sentence.npy\",\n",
      "      \"minilm_embedding_file\": \"embeddings_minilm_sentence.npy\",\n",
      "      \"tfidf_file\": \"tfidf_sentence.pkl\",\n",
      "      \"chroma_nomic_collection\": \"survival_nomic_sentence\",\n",
      "      \"chroma_minilm_collection\": \"survival_minilm_sentence\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'embedding_models': {\n",
    "        'nomic': {\n",
    "            'name': 'nomic-ai/nomic-embed-text-v1.5',\n",
    "            'dims': 768,\n",
    "            'context_length': 8192\n",
    "        },\n",
    "        'minilm': {\n",
    "            'name': 'all-MiniLM-L6-v2',\n",
    "            'dims': 384,\n",
    "            'context_length': 512\n",
    "        }\n",
    "    },\n",
    "    'chunking_methods': chunking_methods,\n",
    "    'retrieval_methods': ['dense_nomic', 'dense_minilm', 'tfidf'],\n",
    "    'collections': {\n",
    "        method: {\n",
    "            'num_chunks': len(chunks_data[method]),\n",
    "            'nomic_embedding_file': f'embeddings_nomic_{method}.npy',\n",
    "            'minilm_embedding_file': f'embeddings_minilm_{method}.npy',\n",
    "            'tfidf_file': f'tfidf_{method}.pkl',\n",
    "            'chroma_nomic_collection': f'survival_nomic_{method}',\n",
    "            'chroma_minilm_collection': f'survival_minilm_{method}'\n",
    "        }\n",
    "        for method in chunking_methods\n",
    "    }\n",
    "}\n",
    "\n",
    "config_file = VECTOR_STORE_DIR / 'retrieval_config.json'\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to {config_file}\")\n",
    "print(\"\\nConfiguration:\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd5919",
   "metadata": {},
   "source": [
    "## 11. Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996a3a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Created:\n",
      "chroma_db/                               (35 files)\n",
      "embeddings_minilm_fixed_size.npy         (  2310.1 KB)\n",
      "embeddings_minilm_page.npy               (  1321.6 KB)\n",
      "embeddings_minilm_sentence.npy           (  2365.6 KB)\n",
      "embeddings_nomic_fixed_size.npy          (  4620.1 KB)\n",
      "embeddings_nomic_page.npy                (  2643.1 KB)\n",
      "embeddings_nomic_sentence.npy            (  4731.1 KB)\n",
      "retrieval_config.json                    (     1.5 KB)\n",
      "tfidf_fixed_size.pkl                     (  3029.8 KB)\n",
      "tfidf_page.pkl                           (  2337.3 KB)\n",
      "tfidf_sentence.pkl                       (  2600.6 KB)\n"
     ]
    }
   ],
   "source": [
    "print(\"Files Created:\")\n",
    "for file in sorted(VECTOR_STORE_DIR.glob('*')):\n",
    "    if file.is_file():\n",
    "        size = file.stat().st_size / 1024\n",
    "        print(f\"{file.name:40s} ({size:8.1f} KB)\")\n",
    "    else:\n",
    "        num_files = len(list(file.rglob('*')))\n",
    "        print(f\"{file.name + '/':<40s} ({num_files} files)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
